В настоящее время для создания модулей лингвистических процессоров применяется два главных подхода: основанный на правилах (rule-based), или инженерный, и основанный на машинном обучении (machine learning).
Исторически первым является подход на правилах, который заключается в описании необходимой лингвистической информации в виде формальных правил. В ранних системах правила были встроены в программный код, сейчас же для записи правил используется либо уже готовый формальный язык, либо подобный язык специально создается для разрабатываемого приложения. Правила создаются лингвистами или специалистами по проблемной области обрабатываемых текстов.
В рамках подхода, основанного на машинном обучении, источником лингвистической информации выступают не правила, а отобранные тексты проблемной области. Среди методов, применяемых в рамках подхода, выделяют методы обучения с учителем (supervised), методы обучения без учителя (unsupervised), методы частичного обучения с учителем (bootstrapping).
Чаще всего применяется обучение с учителем, при котором происходит построение математической и программной модели — машинного классификатора, который умеет распознавать различные классы единиц текста (слов, словосочетаний и других конструкций) или самих текстов. Построение классификатора происходит на специально размеченном текстовом корпусе (обучающей выборке), в котором распознаваемым единицам (или самим текстам) приписаны метки, кодирующие важные признаки распознаваемых единиц/текстов. Обучение представляет собой по сути выявление общих закономерностей, присущих текстам на ЕЯ, на основе данных обучающей выборки.
Оба рассмотренных подхода имеют свои достоинства и недостатки. Создание правил трудоемко и требует достаточно квалифицированного труда, как правило, лингвиста. Очень часто даже лингвист не может предусмотреть заранее все частные случаи, которые надо отразить в правилах.
В то же время правила обычно декларативны и легко понимаемы, поэтому их просто поддерживать: модифицировать и расширять, тем самым отлаживая функционирование процессора. Машинное обучение не требует ручного труда по составлению правил и сокращает время разработки систем, однако необходимы знания для выбора подходящих методов обучения. Кроме того, результирующие модели (классификаторы) непрозрачны для понимания, т. к. не имеют явной лингвистической интерпретации. Также машинное обучение предполагает наличие подходящего размеченного корпуса текстов, что не всегда возможно. Создание такого корпуса в любом случае требует значительных объемов ручного труда.
Сравнивая применение этих подходов, можно заметить, что ранее чаще применялся подход на правилах, поскольку было мало размеченных текстовых корпусов. С появлением различных размеченных данных все чаще прибегают к машинному обучению, как быстрому способу получения нужного приложения КЛ.
Современная тенденция — модульные, многокомпонентные системы автоматической обработки текстов (multi-component, pipelined systems), причем разные модули могут быть созданы в рамках разных подходов, например, модуль графематического анализа — на основе машинного обучения, а морфологического — на основе правил.
Машинное обучение довольно часто применяется для обработки коллекций текстовых документов, с использованием признаковой модели текста, при которой признаки определены для каждого документа по отдельности. Признаками могут выступать различные информационные характеристики текста: как лингвистические, так статистические и структурные: например, частота определенных слов (или их категорий) в документе, частота использования спецзнаков, соотношение частей речи слов, наличие определенных синтаксических конструкций или разделов текста, дата создания и др.
Разновидностями признаковой модели являются модель BOW (bag of words — мешок слов), в которой текст характеризуется набором своих значимых слов (обычно это все знаменательные слова, точнее, их леммы), а также векторная модель текста, в которой указанный набор упорядочен. Векторная модель применяется, например, в информационном поиске, при этом в качестве признаков чаще берутся не слова, а более сложные характеристики, такие как показатель TF-IDF для слов.
Особняком стоит статистическая языковая модель (Language Model), характеризующая язык в целом, а не отдельный текст.
Классическая языковая модель строится по представительному массиву текстов конкретного ЕЯ (например, английского) путем подсчета частот N-грамм слов (т. е. стоящих рядом слов). Чаще всего рассматриваются биграммы (N = 2) и триграммы (N = 3). Модель призвана давать ответ на вопрос, насколько вероятно появление заданного слова, если непосредственно перед ним встречались определенные слова. Вероятности рассчитываются на основе собранной статистики. Такая модель применяется, к примеру, для разрешения лексической неоднозначности. Разновидности модели: N-граммы частей речи слов текста или N-граммы букв текста (возможны и другие модели) применяются для разрешения морфологической омонимии или для выявления опечаток в тексте соответственно.